import torch
import requests
from langchain_huggingface import HuggingFaceEmbeddings

BASE_URL = "http://localhost:8000/api/v2"
COLLECTION_NAME = "google_api_docs"

resp = requests.request("GET", f"{BASE_URL}/healthcheck")
print(f"âœ… {resp.status_code} ì„œë²„ ì •ìƒ ì‹¤í–‰")
print("=" * 50)

# ==============================
# ì‚¬ìš©ì ì •ë³´ í™•ì¸ & tenant/database ì„¤ì •
# ==============================
resp = requests.get(f"{BASE_URL}/auth/identity")
identity = resp.json()


TENANT_NAME = identity["tenant"]
# ì²« ë²ˆì§¸ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©
DATABASE_NAME = identity["databases"][0]

print(f"âœ… ì—°ê²° ì„±ê³µ")
print(f"   Tenant: {TENANT_NAME}")
print(f"   Database: {DATABASE_NAME}")
print("=" * 50)

# ==============================
# ê¸°ì¡´ ì»¬ë ‰ì…˜ ëª©ë¡ ì¡°íšŒ
# ==============================
resp = requests.get(
    f"{BASE_URL}/tenants/{TENANT_NAME}/databases/{DATABASE_NAME}/collections"
)
collections = resp.json()

# ==============================
# ì›í•˜ëŠ” ì»¬ë ‰ì…˜ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±
# ==============================
collection = next((c for c in collections if c["name"] == COLLECTION_NAME), None)

if collection:
    print(f"âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ë°œê²¬")
    collection_id = collection["id"]
    print(f"   ID: {collection_id}")
    print(f"   Dimension: {collection.get('dimension', 'N/A')}")
else:
    print(f"ğŸ“ ì»¬ë ‰ì…˜ '{COLLECTION_NAME}'ì´ ì—†ì–´ì„œ ìƒì„±í•©ë‹ˆë‹¤...")

    # ì»¬ë ‰ì…˜ ìƒì„±
    collection_data = {
        "name": COLLECTION_NAME,
        "metadata": {"description": "Google API documentation collection"},
    }

    resp = requests.post(
        f"{BASE_URL}/tenants/{TENANT_NAME}/databases/{DATABASE_NAME}/collections",
        json=collection_data,
    )
    resp.raise_for_status()

    collection = resp.json()
    collection_id = collection["id"]
    print(f"âœ… ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ")
    print(f"   ID: {collection_id}")

# ìµœì¢… ì •ë³´ ì¶œë ¥
print(f"\nâœ… ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ ì •ë³´:")
print(f"   ì´ë¦„: {COLLECTION_NAME}")
print(f"   ID: {collection_id}")
print(
    f"   ê²½ë¡œ: /tenants/{TENANT_NAME}/databases/{DATABASE_NAME}/collections/{collection_id}"
)
print("=" * 50)


# ===============================
# HTTP API ì¿¼ë¦¬ ì¡°íšŒ
# ===============================
if torch.cuda.is_available():
    device = "cuda"
else:
    device = "cpu"

embeddings = HuggingFaceEmbeddings(
    model_name="BAAI/bge-m3",
    model_kwargs={"device": device},
    encode_kwargs={"normalize_embeddings": True},
)
query_vec = embeddings.embed_query("bigquery insert")

collection_url = f"{BASE_URL}/tenants/{TENANT_NAME}/databases/{DATABASE_NAME}/collections/{collection_id}"

# whereì€ ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì¡°ê±´
# ì˜ˆì‹œ) "where": {"tags": "bigquery"}
# ì˜ë¯¸) metadata["tags"] == "bigquery" ì¸ ì• ë“¤ë§Œ ê²€ìƒ‰

# whereì€ ëª½ê³  ì¿¼ë¦¬ ë¬¸ë²•ì„ ë”°ë¦„
# ì˜ˆì‹œ) "where": {"$or": [{"tags": {"$contains": "bigquery"}}]},
# ì˜ë¯¸) metadata["tags"]ì— "bigquery"ê°€ í¬í•¨ëœ ì• ë“¤ë§Œ ê²€ìƒ‰

# where_documentëŠ” ë¬¸ì„œ ë‚´ìš© ê¸°ë°˜ í•„í„°ë§ ì¡°ê±´
# ì˜ˆì‹œ) "where_document": {"$contains": "bigquery"}
# ì˜ë¯¸) ë¬¸ì„œ ë‚´ìš©ì— "bigquery"ê°€ í¬í•¨ëœ ì• ë“¤ë§Œ ê²€ìƒ‰
# (ì´ ì¡°ê±´ì„ ì“°ì§€ ì•Šìœ¼ë©´ ì»¬ë ‰ì…˜ ì „ì²´ì—ì„œ ì„ë² ë”© ìœ ì‚¬ë„ ê²€ìƒ‰)

# query_embeddings: ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
# n_results: ê° ì¿¼ë¦¬ ë²¡í„°ë‹¹ ê²€ìƒ‰í•  ê²°ê³¼ ìˆ˜
# include: ì‘ë‹µì— í¬í•¨í•  í•„ë“œ ì§€ì • (documents, metadatas, ids, distances)

res = requests.post(
    f"{collection_url}/query",
    json={
        # "where": {"$or": [{"tags": {"$contains": "bigquery"}}]},
        "where": {"tags": "bigquery"},
        # "where_document": {"$contains": "bigquery"},
        "query_embeddings": [query_vec],
        "n_results": 10,
        "include": ["documents", "metadatas", "distances"],
    },
)
result = res.json()

# ===============================
# ê²°ê³¼ flatten
# ===============================
flatten_docs = []
flatten_metas = []
flatten_distances = []

# resultëŠ” 2ì¤‘ ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°: [ì¿¼ë¦¬ ìˆ˜][ê²€ìƒ‰ ê²°ê³¼ ìˆ˜]
for doc_list, meta_list, dist_list in zip(
    result.get("documents", []),
    result.get("metadatas", []),
    result.get("distances", []),
):
    for doc, meta, dist in zip(doc_list, meta_list, dist_list):
        flatten_docs.append(doc)
        flatten_metas.append(meta)
        flatten_distances.append(dist)

# ===============================
# ì¶œë ¥
# ===============================
for i, (doc, meta, dist) in enumerate(
    zip(flatten_docs, flatten_metas, flatten_distances), 1
):
    print(
        f"\n[{i}] ê±°ë¦¬: {dist:.4f}, íŒŒì¼: {meta.get('source_file')}, ì²­í¬ ID: {meta.get('chunk_id')}"
    )
    print(f"íƒœê·¸: {meta.get('tags')}, ì›ë³¸ URL: {meta.get('source')}")
    # print("ë‚´ìš©:\n", doc)
    print("-" * 60)
