import torch
import requests
from langchain_huggingface import HuggingFaceEmbeddings

BASE_URL = "http://localhost:8000/api/v2"
COLLECTION_NAME = "google_api_docs"

resp = requests.request("GET", f"{BASE_URL}/healthcheck")
print(f"âœ… {resp.status_code} ì„œë²„ ì •ìƒ ì‹¤í–‰")
print("=" * 50)

# ==============================
# ì‚¬ìš©ì ì •ë³´ í™•ì¸ & tenant/database ì„¤ì •
# ==============================
resp = requests.get(f"{BASE_URL}/auth/identity")
identity = resp.json()


TENANT_NAME = identity["tenant"]
# ì²« ë²ˆì§¸ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©
DATABASE_NAME = identity["databases"][0]

print(f"âœ… ì—°ê²° ì„±ê³µ")
print(f"   Tenant: {TENANT_NAME}")
print(f"   Database: {DATABASE_NAME}")
print("=" * 50)

# ==============================
# ê¸°ì¡´ ì»¬ë ‰ì…˜ ëª©ë¡ ì¡°íšŒ
# ==============================
resp = requests.get(
    f"{BASE_URL}/tenants/{TENANT_NAME}/databases/{DATABASE_NAME}/collections"
)
collections = resp.json()

# ==============================
# ì›í•˜ëŠ” ì»¬ë ‰ì…˜ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±
# ==============================
collection = next((c for c in collections if c["name"] == COLLECTION_NAME), None)

if collection:
    print(f"âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ë°œê²¬")
    collection_id = collection["id"]
    print(f"   ID: {collection_id}")
    print(f"   Dimension: {collection.get('dimension', 'N/A')}")
else:
    print(f"ğŸ“ ì»¬ë ‰ì…˜ '{COLLECTION_NAME}'ì´ ì—†ì–´ì„œ ìƒì„±í•©ë‹ˆë‹¤...")

    # ì»¬ë ‰ì…˜ ìƒì„±
    collection_data = {
        "name": COLLECTION_NAME,
        "metadata": {"description": "Google API documentation collection"},
    }

    resp = requests.post(
        f"{BASE_URL}/tenants/{TENANT_NAME}/databases/{DATABASE_NAME}/collections",
        json=collection_data,
    )
    resp.raise_for_status()

    collection = resp.json()
    collection_id = collection["id"]
    print(f"âœ… ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ")
    print(f"   ID: {collection_id}")

# ìµœì¢… ì •ë³´ ì¶œë ¥
print(f"\nâœ… ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ ì •ë³´:")
print(f"   ì´ë¦„: {COLLECTION_NAME}")
print(f"   ID: {collection_id}")
print(
    f"   ê²½ë¡œ: /tenants/{TENANT_NAME}/databases/{DATABASE_NAME}/collections/{collection_id}"
)
print("=" * 50)


# ===============================
# HTTP API ì¿¼ë¦¬ ì¡°íšŒ
# ===============================
if torch.cuda.is_available():
    device = "cuda"
elif torch.backends.mps.is_available():
    device = "mps"
else:
    device = "cpu"

embeddings = HuggingFaceEmbeddings(
    model_name="BAAI/bge-m3",
    model_kwargs={"device": device},
    encode_kwargs={"normalize_embeddings": True},
)
query_vec = embeddings.embed_query("map")

collection_url = f"{BASE_URL}/tenants/{TENANT_NAME}/databases/{DATABASE_NAME}/collections/{collection_id}"

res = requests.post(
    f"{collection_url}/query",
    json={
        "query_embeddings": [query_vec],
        "n_results": 1,
        "include": ["documents", "metadatas", "distances"],
    },
)
result = res.json()

# ===============================
# ê²°ê³¼ flatten
# ===============================
flatten_docs = []
flatten_metas = []
flatten_distances = []

# resultëŠ” 2ì¤‘ ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°: [ì¿¼ë¦¬ ìˆ˜][ê²€ìƒ‰ ê²°ê³¼ ìˆ˜]
for doc_list, meta_list, dist_list in zip(
    result.get("documents", []),
    result.get("metadatas", []),
    result.get("distances", []),
):
    for doc, meta, dist in zip(doc_list, meta_list, dist_list):
        flatten_docs.append(doc)
        flatten_metas.append(meta)
        flatten_distances.append(dist)

# ===============================
# ì¶œë ¥
# ===============================
for i, (doc, meta, dist) in enumerate(
    zip(flatten_docs, flatten_metas, flatten_distances), 1
):
    print(
        f"\n[{i}] ê±°ë¦¬: {dist:.4f}, íŒŒì¼: {meta.get('source_file')}, ì²­í¬ ID: {meta.get('chunk_id')}"
    )
    print(f"íƒœê·¸: {meta.get('tags')}, ì›ë³¸ URL: {meta.get('source')}")
    print("ë‚´ìš©:\n", doc)
    print("-" * 60)


# ===============================
# í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰
# ===============================
payload = {
    # "where": "map",
    # "where_document": '{"$contains": "map"}',
    # "ids": ["string"],
    "include": ["metadatas", "documents", "distances"],
    "limit": 10,
    "offset": 10,
}

res = requests.post(f"{collection_url}/get", json=payload)
res.raise_for_status()

result = res.json()
print(f"\n\nâœ… í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ (ì´ {result.get('count', 0)}ê°œ):")

for i, query in enumerate(result.get("results", []), 1):
    print(f"=== Query #{i} ===")
    for j, doc in enumerate(query.get("documents", []), 1):
        metadata = query.get("metadatas", [])[j - 1] if query.get("metadatas") else {}
        print(f"[{j}] íŒŒì¼: {metadata.get('source_file')}")
        print("ë‚´ìš©:\n", doc)
        print("-" * 60)
